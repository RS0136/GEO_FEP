This repository contains the Python code for the fep_geo package used in the analyses of the preprint “A Geometric Free-Energy Framework for Pragmatic Neural Population Codes”. The code implements a geometric free-energy and pragmatics pipeline on the public International Brain Laboratory (IBL) visual decision-making Neuropixels dataset. Each Neuropixels probe insertion is treated as a sender population that emits a message on each trial, represented by a vector of spike counts across units. These messages are embedded in a low-dimensional latent space using factor analysis. A Gaussian prototype geometry in this latent space defines ideal Bayesian listeners, while logistic regression decoders serve as actual listeners. The package computes information-theoretic diagnostics, including information gain and several Kullback–Leibler based “pragmatic losses”, to quantify how efficiently actual listeners exploit the information encoded in the latent representation.

The code supports the full analysis pipeline used in the preprint. It loads spike-sorting outputs and task variables via the IBL ONE and ibllib interfaces, constructs trial-wise world states and block-wise priors, builds peri-stimulus spike-count matrices, fits factor analysis models to obtain latent codes, estimates Gaussian prototypes and a shared covariance, and defines ideal listeners with block priors and with uniform priors. On the same latent codes, it trains logistic regression decoders that are either prior-agnostic or prior-aware. From these listeners it computes trial-wise information gain and four variants of pragmatic loss, aggregates these metrics across sessions and block types, and generates summary figures and tables.

The package targets Python 3.11 (the preprint used Python 3.11.14) and relies on standard scientific libraries such as NumPy, pandas, scikit-learn, and Matplotlib, together with ibllib and ONE-api for IBL data access. All core hyperparameters, including peri-stimulus time windows, latent dimensionality, train and test split, and decoder regularisation, are collected in a configuration module so that analyses are reproducible and easy to modify.

Data are fetched on demand from the public IBL OpenAlyx server. You will need a working ONE configuration and local cache directory. After installing one-api and ibllib, run ONE.setup once to configure the client. The helper functions in the package build an ONE instance, download spikes, clusters, channels, and trials for each probe insertion, and wrap them in simple data classes used by the rest of the analysis.

Typical use follows three steps. First, install the required Python packages in a virtual environment and ensure that the repository root is on your PYTHONPATH so that “import fep_geo” succeeds. Second, configure IBL access via ONE so that Neuropixels sessions can be downloaded automatically. Third, run the command-line entry points from the repository root to reproduce the analyses.

The main entry point is “python -m fep_geo.run_all_sessions --output-root results”. This runs the full pipeline for all probe insertion IDs listed in the configuration: data loading, trial selection, latent geometry, ideal and actual listeners, trial-wise metrics, and per-session figures. It writes results into an output directory that contains per-session subfolders with tables and figures, and cross-session aggregate tables and plots. Command-line options allow you to change the output location, select a subset of sessions, or skip figure generation.

Additional convenience entry points are provided. The command “python -m fep_geo.run_extras --output-root results” recomputes and writes the summary tables for test-only metrics, prior-aware control decoders, and basic neural–behaviour links without regenerating all per-session figures. The command “python -m fep_geo.run_robustness --output-root results” runs robustness analyses over latent dimensionality, peri-stimulus time window, and logistic regression hyperparameters, writing a grid summary of decoding accuracies, information gains, and pragmatic losses. The command “python -m fep_geo.run_toy_ig_examples --output-root results” generates simple one-dimensional toy examples and plots that illustrate the scale of information gain and pragmatic loss.

Internally, the code is organised as a small library. There are modules for configuration, data I/O, trial construction, latent geometry, listeners, metrics, aggregation, behaviour, and plotting. The configuration module defines data classes that hold all analysis options and default settings. The data I/O module wraps the ONE client and returns a raw session object with spikes, clusters, channels, and trials. The trials module builds valid-trial masks, world labels, contexts, and peri-stimulus spike-count matrices. The geometry module fits factor analysis to spike counts and constructs Gaussian prototypes and Mahalanobis distances. The listeners module defines ideal listeners in latent space and logistic actual listeners, including a variant that receives the block prior as an additional feature. The metrics module computes information gain and four KL-based pragmatic losses for each trial. The aggregation module runs the full per-session pipeline and builds cross-session summary tables. Plotting modules generate single-session figures, cross-session summaries, robustness plots, and toy example plots.

Reproducibility is supported in several ways. Random seeds for train and test splits and model fitting are fixed in the default configuration. Factor analysis is fitted on training trials only, while Gaussian prototypes and covariances are usually estimated from all valid trials to stabilise the ideal listener; test-only metrics are computed as a control and reproduce the all-trial summaries closely. The robustness scripts systematically vary key hyperparameters and confirm that the qualitative patterns in decoding accuracy, information gain, and pragmatic loss are stable across reasonable settings.
